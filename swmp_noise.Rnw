\documentclass[letterpaper,12pt,oneside]{article}
\usepackage[paperwidth=8.5in,paperheight=11in,top=1in,bottom=1in,left=1in,right=1in]{geometry}
\usepackage{setspace}
% \usepackage[colorlinks=true,allcolors=Blue]{hyperref}
\usepackage[hidelinks]{hyperref}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{indentfirst}
\usepackage{titlesec}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{rotating}
\usepackage{tabularx}
\usepackage{outlines}
\usepackage{lineno}
\usepackage{array}
\usepackage{times}
\usepackage{cleveref}
\usepackage{acronym}
\usepackage[position=t]{subfig}
\usepackage{paralist}
\usepackage[noae]{Sweave}
\usepackage{natbib}
\usepackage{array}
\usepackage{pdflscape}
\usepackage{bm}
% \usepackage{showlabels}
\bibpunct{(}{)}{;}{a}{}{,}

% page margins and section title formatting
\linespread{1.5}
\setlength{\footskip}{0.5in}
\titleformat*{\section}{\Large\bf\em}
\titleformat*{\subsection}{\singlespace\large\bf}
\titleformat*{\subsubsection}{\singlespace\normalsize\bf\em}
\titlespacing{\section}{0in}{0in}{0in}
\titlespacing{\subsection}{0in}{0in}{0in}
\titlespacing{\subsubsection}{0in}{0in}{0in}

% cleveref options
\crefname{table}{Table}{Tables}
\crefname{figure}{Fig.}{Figs.}
\renewcommand{\figurename}{Fig.}

% aliased citations
\defcitealias{CDMO14}{CDMO 2014}
\defcitealias{NRC00}{NRC 2000}
\defcitealias{RDCT14}{RDCT 2014}

% acronyms
\acrodef{DO}[DO]{dissolved oxygen}
\acrodef{EPA}[EPA]{Environmental Protection Agency}
\acrodef{NERRS}[NERRS]{National Estuarine Research Reserve System}
\acrodef{RMSE}[RMSE]{root mean square error}
\acrodef{SWMP}[SWMP]{System Wide Monitoring Program}
\acrodef{WRTDS}[WRTDS]{weighted regression on time, discharge, and season}

% assorted functions
% for multiple rows in table headers
\newcommand{\head}[2]{\multicolumn{1}{>{\arraybackslash}p{#1}}{#2}}
% for milligrams per litre
\newcommand{\mgl}{mg L$^{-1}$}

% hides (not removes) numbering for section, subsection, etc.
% left indents
\renewcommand{\thesection}{}
\renewcommand{\thesubsection}{}
\renewcommand{\thesubsubsection}{}
\makeatletter
\def\@seccntformat#1{\csname #1ignore\expandafter\endcsname\csname the#1\endcsname\quad}
\let\sectionignore\@gobbletwo
\def\@subseccntformat#1{\csname #1ignore\expandafter\endcsname\csname the#1\endcsname\quad}
\let\subsectionignore\@gobbletwo
\def\@subsubseccntformat#1{\csname #1ignore\expandafter\endcsname\csname the#1\endcsname\quad}
\let\subsubsectionignore\@gobbletwo
\let\latex@numberline\numberline
\def\numberline#1{\if\relax#1\relax\else\latex@numberline{#1}\fi}
\makeatother

% dependent data
<<dep_dat, eval = T, echo = F, cache = F, results = 'hide', child = 'dep_dat.Rnw'>>=
@

%knitr options
<<setup, cache = F, echo = F>>=
# set global chunk options
opts_chunk$set(fig.align = 'center', message = F, dev = 'pdf', dev.args = list(family = 'serif'), fig.pos = '!ht', warning = F, echo = F)
options(replace.assign=TRUE,width=90,digits=1)
@

\begin{document}

\raggedbottom
% \linenumbers
\raggedright
\urlstyle{same}
\setlength{\parindent}{0.5in}
\renewcommand\refname{References \vspace{12pt}}

%%%%%%
% title page
\input{titlepage.tex}

%%%%%%
% abstract
\newpage
\section{Abstract}
<<intro, child = 'abstract.Rnw'>>=
@

\acresetall
\clearpage

%%%%%%
% intro
\section{Introduction} \label{intro}
<<intro, child = 'intro.Rnw'>>=
@

%%%%%%
% materials and procedures
\section{Materials and Procedures}
<<mat_proc, child = 'mat_proc.Rnw'>>=
@

%%%%%%
% assessment
\section{Assessment}
<<assess, child = 'assess.Rnw'>>=
@

%%%%%%
% discussion
\section{Discussion}
<<discussion, child = 'discussion.Rnw'>>=
@

%%%%%%
% comments and recs
\section{Comments and recommendations}
<<comments, child = 'comments.Rnw'>>=
@

%%%%%%
% refs
\clearpage
\begin{singlespace}
\bibliographystyle{apalike_mine}
\bibliography{ref_diss}
\end{singlespace}
\clearpage

%%%%%%
% acknowledgments
\section{Acknowledgments}

We acknowledge the significant efforts of research staff and field crews from the \acl{SWMP} of the \acl{NERRS} for providing access to high quality data sets.  We thank Dr. Jane Caffrey and Dr. Erik Smith for reviewing early drafts of the manuscript. The views expressed in this article are those of the authors and do not necessarily reflect the views or policies of the U.S. Environmental Protection Agency.

%%%%%%
% multimedia files, appendices

\section{Multimedia} \label{multi}
\input{multimedia.tex}
\clearpage

%%%%%%
% figures

\section{Figures}

% example of creating simulated time series
\centering\vspace*{\fill}
<<do_sim, eval = T, echo = F, cache = T, fig.width = 7, fig.height = 6, eval.after='fig.cap', fig.cap = 'Example of each component of a simulated \\ac{DO} time series for testing weighted regression.  The time series were created using \\cref{do_obs,do_bio,do_unc,do_obs_all,do_sin,do_unc_n,deltdo,deltx,do_advp,do_adv}. Yellow indicates a twelve hour daylight period beginning at 630 each day.'>>=
# create time vector
vec <- c('2014-05-01 00:00:00', '2014-05-31 00:00:00')
vec <- as.POSIXct(vec, format = '%Y-%m-%d %H:%M:%S')
vec <- seq(vec[1], vec[2], by = 60*30)

# create simulated time series of DO, tide, etc.
DO_sim <- ts_create(
  vec, 
  do.amp = 2, 
  tide_cat = 'Mixed Semidiurnal', 
  tide_assoc = 4,
  err_rng_obs = 2, 
  err_rng_pro = 2, 
  seeded = T
  )  

levs <- c('e_obs', 'e_pro', 'DO_unc', 'DO_die', 'DO_bio', 'DO_adv', 'DO_obs')
to.plo <- melt(DO_sim, id.var = c('Day', 'sunrise'),
  measure.var = levs
  )
to.plo$variable <- factor(to.plo$variable, levels = levs)

ylab<-expression(paste('DO (mg ',L^-1,')'))
p <- ggplot(to.plo, aes(x = Day, y = value, col = sunrise)) +
  geom_line() +
  facet_wrap(~ variable, scales = 'free_y', ncol = 1) + 
  theme_bw() +
  ylab(ylab) + 
  scale_colour_gradientn(colours = c('orange', 'black')) +
  theme(legend.position = 'none')
 
facet_wrap_labeller(p, labels = c(
  expression(italic(epsilon [ obs])),
  expression(italic(epsilon [pro])),
  expression(italic(
    paste(DO [unc], '=', epsilon [ obs] + epsilon [ pro]))),
  expression(italic(DO [die])),
  expression(italic(paste(DO [bio], '=', DO [die] + DO [unc]))), 
  expression(italic(DO [adv])),
  expression(italic(paste(DO [obs], '=', DO [bio] + DO [adv])))
  ))
@
\vfill
\clearpage

% plot of representative time series for simulation
\centering\vspace*{\fill}
<<sim_ex, fig.height = 4, fig.width = 7, out.width = '\\textwidth', cache = T, echo = F, eval = T, fig.cap = 'Representative examples of simulated time series of observed \\ac{DO} ($DO_{obs}$, blue lines) and biological \\ac{DO} ($DO_{bio}$, as a component of observed, red lines) created by varying each of four parameters: strength of tidal association with \\ac{DO} signal ($DO_{adv}$), amount of process uncertainty ($\\varepsilon_{pro}$), amount of observation uncertainty ($\\varepsilon_{obs}$), and strength of diel \\ac{DO} component ($DO_{die}$).  Parameter values represent the minimum and maximum used in the simulations as mg L$^{-1}$ of \\ac{DO}.'>>=
load('data/eval_grd.RData')

# find rows in eval_grd of parms to plot
sel_vec <- !with(eval_grd,
  bio_rng %in% 1|
  tide_assoc %in% 1|
  err_rng_pro %in% 1|
  err_rng_obs %in% 1
  )
parms <- eval_grd[sel_vec,]
parms$L1 <- as.numeric(row.names(parms))

# create simulated time series of DO, tide, etc., representatives
vec <- c('2014-05-01 00:00:00', '2014-05-31 00:00:00')
vec <- as.POSIXct(vec, format = '%Y-%m-%d %H:%M:%S')
vec <- seq(vec[1], vec[2], by = 60*30)
to_plo <- alply(parms,
  1,
  .fun = function(x) {
  ts_create(vec, 
    do.amp = x$bio_rng, 
    tide_cat = x$tide_cat, 
    tide_assoc = x$tide_assoc, 
    err_rng_obs = x$err_rng_obs, 
    err_rng_pro = x$err_rng_pro, 
    seeded = T)
    }
  )
names(to_plo) <- rownames(parms)

# prep for plotting
to_plo <- melt(to_plo, id.var = names(to_plo[[1]]))
to_plo <- merge(to_plo, parms, by = 'L1', all.x = T)

# rename extremes for facet labs
labs <- paste('Bio Amp', unique(to_plo$bio_rng))
to_plo$bio_rng <- factor(to_plo$bio_rng, labels = labs)
labs <- paste('Assoc', unique(to_plo$tide_assoc))
to_plo$tide_assoc <- factor(to_plo$tide_assoc, labels = labs)
labs <- paste('Noise pro', unique(to_plo$err_rng_pro))
to_plo$err_rng_pro <- factor(to_plo$err_rng_pro, labels = labs)
labs <- paste('Noise obs', unique(to_plo$err_rng_obs))
to_plo$err_rng_obs <- factor(to_plo$err_rng_obs, labels = labs)

# setup facet labels
facet1_names <- list(
  'Assoc 0' = expression(paste(italic(DO [adv]), ' 0')), 
  'Assoc 2' = expression(paste(italic(DO [adv]), ' 2'))
  )
facet2_names <- list(
  'Bio Amp 0' = expression(paste(italic(DO [die]), ' 0')), 
  'Bio Amp 2' = expression(paste(italic(DO [die]), ' 2'))
  )
facet3_names <- list(
  'Noise pro 0' = expression(paste(italic(epsilon [pro]), ' 0')), 
  'Noise pro 2' = expression(paste(italic(epsilon [pro]), ' 2'))
  )
facet4_names <- list(
  'Noise obs 0' = expression(paste(italic(epsilon [obs]), ' 0')), 
  'Noise obs 2' = expression(paste(italic(epsilon [obs]), ' 2'))
  )
plot_labeller <- function(variable,value){
  if (variable=='tide_assoc')
    return(facet1_names[value])
  if (variable=='bio_rng')
    return(facet2_names[value])
  if (variable=='err_rng_pro')
    return(facet3_names[value])
  if (variable=='err_rng_obs')
    return(facet4_names[value])
  }

cols <- ggplotColours(2)
ggplot(to_plo, aes(x = Day, y = DO_obs, group = L1)) + 
  geom_line(aes(colour = 'Observed'), alpha = 0.7) +
  geom_line(aes(y = DO_bio, colour = 'Biological'), alpha = 0.7) +
  theme_bw() + 
  scale_colour_manual(
    labels = expression(italic(DO [bio]), italic(DO [obs])),
    values = cols
    ) +
  theme(legend.position = 'top', 
    legend.title = element_blank(), 
    axis.text = element_text(size = 8)
    ) + 
  ylab(expression(paste('DO (mg ', L^-1, ')'))) +
  facet_grid(err_rng_obs + err_rng_pro ~ bio_rng + tide_assoc, 
    labeller = plot_labeller) 
@
\vfill
\clearpage

% example of error surfaces 
\centering\vspace*{\fill}
<<err_surf1, fig.height = 3.5, fig.width = 5.5, cache = T, echo = F, eval = T, fig.cap = "Heat maps of correlations and errors (\\ac{RMSE}) for filtered \\ac{DO} time series ($DO_{dtd}$) from weighted regression with `true' biological \\ac{DO} ($DO_{bio}$) for varying simulation parameters: strength of tidal association with \\ac{DO} signal ($DO_{adv}$), amount of process uncertainty ($\\varepsilon_{pro}$), amount of observation uncertainty ($\\varepsilon_{obs}$), and strength of diel \\ac{DO} component ($DO_{die}$).  Each tile represents the correlation or error from results for a given combination of simulation parameters averaged for all window widths (as in \\cref{fig:err_surf2}).  See \\cref{tab:dtd_perf1} for a summary of combined results for each unique parameter.">>=

# load summary of model performance for simulations
load('data/mod_perf.RData')

to_plo <- mod_perf

# aggregate for simpler plot
to_plo <- ddply(
  to_plo, 
  .variable = c('bio_rng', 'tide_assoc', 'err_rng_pro', 'err_rng_obs'),
  .fun = function(x) data.frame(cor = mean(x$cor), err = mean(x$err))
  )

# reassign factor labels for bio amp and tidal assoc
labs <- paste('Bio Amp', unique(to_plo$bio_rng))
to_plo$bio_rng <- factor(to_plo$bio_rng, labels = labs)
labs <- paste('Assoc',unique(to_plo$tide_assoc))
to_plo$tide_assoc <- factor(to_plo$tide_assoc, labels = labs)

# setup facet labels
facet1_names <- list(
  'Bio Amp 0' = expression(paste(italic(DO [die]), ' 0')), 
  'Bio Amp 1' = expression(paste(italic(DO [die]), ' 1')),
  'Bio Amp 2' = expression(paste(italic(DO [die]), ' 2'))
  )
facet2_names <- list(
  'Assoc 0' = expression(paste(italic(DO [adv]), ' 0')), 
  'Assoc 1' = expression(paste(italic(DO [adv]), ' 1')),
  'Assoc 2' = expression(paste(italic(DO [adv]), ' 2'))
  )

plot_labeller <- function(variable,value){
  if (variable=='tide_assoc')
    return(facet1_names[value])
  if (variable=='bio_rng')
    return(facet2_names[value])
  }

mat_theme <-   theme(
    panel.margin = unit(0, 'lines'), 
    strip.text = element_text(size = 8),
    legend.text = element_text(size = 8),
    legend.position = 'top',
    axis.text = element_text(size = 8)
    )

p1 <- ggplot(to_plo, aes(x = factor(err_rng_pro), y = factor(err_rng_obs), z = cor, fill = cor)) + 
  geom_tile() +
  facet_grid(bio_rng ~ tide_assoc,
    labeller = plot_labeller) +
  scale_fill_gradientn(name = 'Correlation', 
    colours = brewer.pal(9, 'GnBu')#, limits = c(0, 1)
    ) +
  scale_x_discrete(expand = c(0,0)) + 
  scale_y_discrete(expand = c(0,0)) +
  xlab(expression(italic(epsilon [pro]))) +
  ylab(expression(italic(epsilon [obs]))) + 
  theme_bw() +
  mat_theme

p2 <- ggplot(to_plo, aes(x = factor(err_rng_pro), y = factor(err_rng_obs), z = err, fill = err)) + 
  geom_tile() +
  facet_grid(bio_rng ~ tide_assoc,
    labeller = plot_labeller) +
  scale_fill_gradientn(name = 'RMSE', 
    colours = rev(brewer.pal(9, 'GnBu')), limits = c(0, 2.5)
    ) +
  scale_x_discrete(expand = c(0,0)) + 
  scale_y_discrete(expand = c(0,0)) +
  xlab(expression(italic(epsilon [pro]))) +
  ylab(expression(italic(epsilon [obs]))) + 
  theme_bw() +
  mat_theme

grid.arrange(p1, p2, ncol = 2)

@
\vfill
\clearpage

% example of error surfaces 
\centering\vspace*{\fill}
<<err_surf2, fig.height = 2.33, fig.width = 6, cache = T, echo = F, eval = T, fig.cap = "Heat maps of correlations and errors (\\ac{RMSE}) for filtered \\ac{DO} time series ($DO_{dtd}$) from weighted regression with `true' biological \\ac{DO} ($DO_{bio}$) for varying half window widths: days, hour of day, and proportion of tidal range.  Each tile represents the correlation or error from results for a given combination of window widths averaged for all simulation parameters (as in \\cref{fig:err_surf1}).  See \\cref{tab:dtd_perf2} for a summary of combined results for each unique window.">>=

options(digits=3)

# load summary of model performance for simulations
load('data/mod_perf.RData')

to_plo <- mod_perf

# aggregate for simpler plot
to_plo <- ddply(
  to_plo, 
  .variable = c('dec_time', 'hour', 'Tide'),
  .fun = function(x) data.frame(cor = mean(x$cor), err = mean(x$err))
  )

# reassign factor labels for windows
labs <- paste('Tide', unique(to_plo$Tide))
to_plo$Tide <- factor(to_plo$Tide, labels = labs)

mat_theme <-   theme(
    panel.margin = unit(0, 'lines'), 
    strip.text = element_text(size = 8),
    legend.text = element_text(size = 8),
    legend.position = 'top',
    axis.text = element_text(size = 8)
    )

p1 <- ggplot(to_plo, aes(x = factor(dec_time), y = factor(hour), z = cor, fill = cor)) + 
  geom_tile() +
  facet_grid(~ Tide) +
  scale_fill_gradientn(name = 'Correlation', 
    colours = brewer.pal(9, 'GnBu'),
    labels = format(seq(0.62, 0.7, by = 0.02), nsmall = 1),
    limits = c(0.62, 0.7),
    breaks = seq(0.62, 0.7, by = 0.02)
    ) +
  scale_x_discrete(expand = c(0,0)) +
  scale_y_discrete(expand = c(0,0)) +
  xlab('Days') +
  ylab('Hours') + 
  theme_bw() +
  mat_theme

p2 <- ggplot(to_plo, aes(x = factor(dec_time), y = factor(hour), z = err, fill = err)) + 
  geom_tile() +
  facet_grid(~ Tide) +
  scale_fill_gradientn(name = 'RMSE', 
    colours = rev(brewer.pal(9, 'GnBu')), 
    labels = format(seq(1.08, 1.2, by = 0.04), nsmall = 1),
    limits = c(1.08, 1.2),
    breaks = seq(1.08, 1.2, by = 0.04)
    ) +
  scale_x_discrete(expand = c(0,0)) + 
  scale_y_discrete(expand = c(0,0)) +
  xlab('Days') +
  ylab('Hours') + 
  theme_bw() +
  mat_theme

grid.arrange(p1, p2, ncol = 2)

options(digits=1)
@
\vfill
\clearpage

% maps of each case
\centering\vspace*{\fill}
<<case_map, cache = T, fig.height = 5, fig.width = 8, eval = T, echo = F, fig.cap = 'Locations of \\ac{NERRS} sites used as case studies to validate weighted regression.  Stations at each reserve are ELKVM (Vierra Mouth at Elkhorn Slough), PDBBY (Bayview Channel at Padilla Bay), RKBMB (Middle Blackwater River at Rookery Bay), and SAPDC (Dean Creek at Sapelo Island).'>>=

# low do/high tide, high do/low tide, low do/low tide, high do/low tide
cases <- c('ELKVM', 'PDBBY', 'RKBMB', 'SAPDC')

# zooms for each case, larger is more zoom
zooms <- c(13, 13, 12, 15)

require(ggmap)

# breaks on map
myBreaks <- function(x){
    breaks <- round(quantile(x, probs = c(0.1, 0.5, 0.9)), 2)
    names(breaks) <- attr(breaks,"labels")
    breaks
  }

for(case in cases){
  
  case_meta <- get_map_meta(case)
  
  mapImageData<-get_map(
    location=c(lon=mean(case_meta$Longitude),lat=mean(case_meta$Latitude)),
    source='google',
    maptype='satellite',
    zoom = zooms[case == cases]
    )
  
  reserve <- trim.trailing(unique(case_meta$Reserve.Name))
  
  p <- ggmap(mapImageData,
    extent = "device", 
    base_layer=ggplot(data=case_meta, aes(x =Longitude, 
      y=Latitude, group='Station.Code'))
      ) + 
    geom_point(size = 3, colour = 'lightblue') +
    geom_text(data=case_meta,aes(x=Longitude,y=Latitude,label=Station,
      hjust=0.4,vjust=2),size=5, colour = 'lightblue') +
    ggtitle(reserve) +
    theme(axis.title = element_blank(), axis.text = element_text(size = 8)) +
    scale_x_continuous(breaks = myBreaks) +
    scale_y_continuous(breaks = myBreaks)
  
  assign(paste0('p', which(case == cases)), p)
  
  }


# for us map
meta <- get_map_meta(cases)
meta <- meta[, c('Longitude', 'Latitude','Reserve.Name')]

# create viewports
# vp.1 <- viewport(height=unit(.32, "npc"), width=unit(0.5, "npc"), 
#                            just=c("left","top"), 
#                            y=0.67, x=0)
# vp.2 <- viewport(height=unit(.32, "npc"), width=unit(0.5, "npc"), 
#                            just=c("left","top"), 
#                            y=0.67, x=0.5)
# vp.3 <- viewport(height=unit(.32, "npc"), width=unit(0.5, "npc"), 
#                            just=c("left","top"), 
#                            y=0.33, x=0)
# vp.4 <- viewport(height=unit(.32, "npc"), width=unit(0.5, "npc"), 
#                            just=c("left","top"), 
#                            y=0.33, x=0.5)
# 
# par(mfrow = c(3, 1), mar = numeric(4))
# grob({
  map('state', col = alpha('black', 0.4), ylim = c(23, 50))
  points(meta[, c('Longitude', 'Latitude')], cex =2, pch = 16)
  text(meta$Longitude, meta$Latitude, meta$Reserve.Name, pos = 4, cex = 1.5)
  map.scale(x = -122, y = 26)
#   })
# print(p1, vp=vp.1)
# print(p2, vp=vp.2)
# print(p3, vp=vp.3)
# print(p4, vp=vp.4)

@
\vfill
\clearpage

% example from SAPHD, phase out
\centering\vspace*{\fill}
<<phase_out, cache = T, fig.height = 3, fig.width = 5.5, out.width = '0.8\\textwidth', eval = T, echo = F, fig.cap = 'Continuous \\ac{DO} time series before (observed) and after (filtered) filtering with weighted regression (top) and tidal height (m) colored by total photosynthetically active radiation (bottom, $\\mu$E m$^{-2}$ s$^{-1}$). Results are for the Sapelo Island station for a seven day period when high tide events were out of phase with diel periods, creating lower than expected observed \\ac{DO} during astronomical night and day periods. Filtered values are based on a weighted regression with half window widths of six days, one hour within each day, and tidal height proportion of one half.'>>=
######
# SAPHD example

load('data/case_grds.RData')

# subsets by case. date range, window comb
case <- 'SAPDC'
dat.rng<-as.Date(c('2012-02-01','2012-02-14')) 
sel_vec <- with(case_grds, which(dec_time == casewins[['SAPDC']][[1]] & hour == casewins[['SAPDC']][[2]] & Tide == casewins[['SAPDC']][[3]]))
sel_vec <- paste0(case, '_wtreg_', sel_vec, '.RData')

load(paste0('wtreg/', sel_vec))
inst_subs <- get(gsub('.RData', '', sel_vec))

tzone <- attr(inst_subs$DateTimeStamp, 'tzone')

inst_subs$Date <- as.Date(inst_subs$DateTimeStamp, tz = tzone)
inst.rng <- inst_subs$Date<=dat.rng[2] & inst_subs$Date>=dat.rng[1]
inst_subs <- inst_subs[inst.rng,]

# category for plotting
inst_subs$cats <- 'out'
inst_subs$cats[inst_subs$Date > as.Date('2012-02-07')] <- 'in'

# convert totpar (mmol m2 per 15 minutes) to microeinstens per second
# 1 einstein is 1 mol of photon, milli to micro x 1000, 15 min to sec divide by 900
inst_subs$TotPAR <- 1000/900 * inst_subs$TotPAR

##
# custom theme, mod of theme_b
my_theme <- theme(
  legend.position = 'top',
  axis.title.x = element_blank(),legend.box= 'horizontal',
  plot.margin= unit(c(0, 1, 0, 1), "lines") # top right bottom left
  )

# function for setting range on y axis
rng.fun<-function(vec.in){
  rngs<-range(vec.in,na.rm=T)
  buffs<-0.07*abs(diff(rngs))
  c(rngs[1]-buffs,rngs[2]+buffs)
  }

##
# out of phase plots

# DO plot
to_plo <- met.day.fun(inst_subs, case)
to_plo <- to_plo[to_plo$cats %in% 'out', ]
names(to_plo)[names(to_plo) %in% 'variable'] <- 'solar'
ggpoly1 <- poly.fun(to_plo$solar, to_plo, for_leg = T)
ggpoly2 <- poly.fun(to_plo$solar, to_plo)

ylab<-expression(paste('DO (mg ',L^-1,')'))
p1 <- ggplot(to_plo, aes(x = DateTimeStamp)) + 
  ggpoly1 +
  geom_line(aes(y = DO_obs, colour = 'Observed')) +
  geom_line(aes(y = DO_nrm, colour = 'Filtered')) +
  coord_cartesian(ylim = c(1, 9.5)) +
  scale_fill_manual(values='orange',labels='Day') +
  theme_bw() +
  scale_y_continuous(ylab) +
  my_theme +
  theme(legend.title = element_blank())

#
# tide plot
ylab<-expression(paste('Height (m)'))
p2 <- ggplot(to_plo, aes(x = DateTimeStamp)) + 
  ggpoly2 +
  geom_line(aes(y = Tide, colour = TotPAR)) +
  coord_cartesian(ylim = rng.fun(to_plo$Tide)) +
  theme_bw() +  
  my_theme + 
  scale_y_continuous(ylab) +
  scale_colour_gradient(expression(paste("Total PAR (", italic('\u03BC'), "E ", m^-2, ' ', s^-1, ")")), low='blue', high='yellow',
    guide = guide_colorbar(direction = "horizontal",barheight= 0.4)) +
  theme(legend.title.align = 1)

# get common legend, remove from p1
mylegend1 <- g_legend(p1)
mylegend2 <- g_legend(p2)
p1 <- p1 + theme(legend.position = 'none')
p2 <- p2 + theme(legend.position = 'none')


# Get the widths
pA <- ggplot_gtable(ggplot_build(p1))
pB <- ggplot_gtable(ggplot_build(p2))
maxWidth = unit.pmax(pA$widths[2:3], pB$widths[2:3])

# Set the widths
pA$widths[2:3] <- maxWidth
pB$widths[2:3] <- maxWidth

# first plot
grid.arrange(
  arrangeGrob(mylegend1, mylegend2, ncol = 1),    
  arrangeGrob(pA, pB, ncol = 1),
  ncol = 1, heights = c(2,5)
)

@
\vfill
\clearpage

% example from SAPHD, phase in
\centering\vspace*{\fill}
<<phase_in, cache = T, fig.height = 3, fig.width = 5.5, out.width = '0.8\\textwidth', eval = T, echo = F, fig.cap = 'Continuous \\ac{DO} time series before (observed) and after (filtered) filtering with weighted regression (top) and tidal height (m) colored by total photosynthetically active radiation (bottom, $\\mu$E m$^{-2}$ s$^{-1}$). Results are for the Sapelo Island station for a seven day period when high tide events were in phase with diel periods, creating higher than expected observed \\ac{DO} during astronomical night and day periods. Filtered values are based on a weighted regression with half window widths of six days, one hour within each day, and tidal height proportion of one half.'>>=
######
# SAPHD example

load('data/case_grds.RData')

# subsets by case. date range, window comb
case <- 'SAPDC'
dat.rng<-as.Date(c('2012-02-01','2012-02-14')) 
sel_vec <- with(case_grds, which(dec_time == casewins[['SAPDC']][[1]] & hour == casewins[['SAPDC']][[2]] & Tide == casewins[['SAPDC']][[3]]))
sel_vec <- paste0(case, '_wtreg_', sel_vec, '.RData')

load(paste0('wtreg/', sel_vec))
inst_subs <- get(gsub('.RData', '', sel_vec))

tzone <- attr(inst_subs$DateTimeStamp, 'tzone')

inst_subs$Date <- as.Date(inst_subs$DateTimeStamp, tz = tzone)
inst.rng <- inst_subs$Date<=dat.rng[2] & inst_subs$Date>=dat.rng[1]
inst_subs <- inst_subs[inst.rng,]

# category for plotting
inst_subs$cats <- 'out'
inst_subs$cats[inst_subs$Date > as.Date('2012-02-07')] <- 'in'

# convert totpar (mmol m2 per 15 minutes) to microeinstens per second
# 1 einstein is 1 mol of photon, milli to micro x 1000, 15 min to sec divide by 900
inst_subs$TotPAR <- 1000/900 * inst_subs$TotPAR

##
# custom theme, mod of theme_b
my_theme <- theme(
  legend.position = 'top',
  axis.title.x = element_blank(),legend.box= 'horizontal',
  plot.margin= unit(c(0, 1, 0, 1), "lines") # top right bottom left
  )

# function for setting range on y axis
rng.fun<-function(vec.in){
  rngs<-range(vec.in,na.rm=T)
  buffs<-0.07*abs(diff(rngs))
  c(rngs[1]-buffs,rngs[2]+buffs)
  }

##
# out of phase plots

# DO plot
to_plo <- met.day.fun(inst_subs, case)
to_plo <- to_plo[!to_plo$cats %in% 'out', ]
names(to_plo)[names(to_plo) %in% 'variable'] <- 'solar'
ggpoly1 <- poly.fun(to_plo$solar, to_plo, for_leg = T)
ggpoly2 <- poly.fun(to_plo$solar, to_plo)

ylab<-expression(paste('DO (mg ',L^-1,')'))
p1 <- ggplot(to_plo, aes(x = DateTimeStamp)) + 
  ggpoly1 +
  geom_line(aes(y = DO_obs, colour = 'Observed')) +
  geom_line(aes(y = DO_nrm, colour = 'Filtered')) +
  coord_cartesian(ylim = c(1, 9.5)) +
  scale_fill_manual(values='orange',labels='Day') +
  theme_bw() +
  scale_y_continuous(ylab) +
  my_theme +
  theme(legend.title = element_blank())

#
# tide plot
ylab<-expression(paste('Height (m)'))
p2 <- ggplot(to_plo, aes(x = DateTimeStamp)) + 
  ggpoly2 +
  geom_line(aes(y = Tide, colour = TotPAR)) +
  coord_cartesian(ylim = rng.fun(to_plo$Tide)) +
  theme_bw() +  
  my_theme + 
  scale_y_continuous(ylab) +
  scale_colour_gradient(expression(paste("Total PAR (", italic('\u03BC'), "E ", m^-2, ' ', s^-1, ")")), low='blue', high='yellow',
    guide = guide_colorbar(direction = "horizontal",barheight= 0.4)) +
  theme(legend.title.align = 1)

# get common legend, remove from p1
mylegend1 <- g_legend(p1)
mylegend2 <- g_legend(p2)
p1 <- p1 + theme(legend.position = 'none')
p2 <- p2 + theme(legend.position = 'none')

##
# in phase plots

# Get the widths
pA <- ggplot_gtable(ggplot_build(p1))
pB <- ggplot_gtable(ggplot_build(p2))
maxWidth = unit.pmax(pA$widths[2:3], pB$widths[2:3])

# Set the widths
pA$widths[2:3] <- maxWidth
pB$widths[2:3] <- maxWidth

# plot
grid.arrange(
  arrangeGrob(mylegend1, mylegend2, ncol = 1),    
  arrangeGrob(pA, pB, ncol = 1),
  ncol = 1, heights = c(2,5)
  )

@
\vfill
\clearpage

% example from SAPDC
\centering\vspace*{\fill}
<<case_ex, cache = T, fig.height = 2.5, fig.width = 5.5, out.width = '0.8\\textwidth', eval = T, echo = F, fig.cap = 'Example of daily mean metabolism (net ecosystem metabolism, gross production, and total respiration) before (observed) and after (filtered) filtering with weighted regression. Results are for the Sapelo Island station for a two week period in February, 2012 when high tide was out of phase with the diel cycle during the first week (\\cref{fig:phase_out}) and in phase during the second week (\\cref{fig:phase_in}).'>>=
######
# SAPDC example

load('data/met_ls.RData')
load('data/case_grds.RData')

# subsets by case. date range, window comb
case <- 'SAPDC'
dat.rng<-as.Date(c('2012-02-01','2012-02-14')) 
sel_vec <- with(case_grds, which(dec_time == casewins[['SAPDC']][[1]] & hour == casewins[['SAPDC']][[2]] & Tide == casewins[['SAPDC']][[3]]))
sel_vec <- paste0(case, '_wtreg_', sel_vec, '.RData')

# select case, window
met_subs <- met_ls[[grep(sel_vec, names(met_ls))]]

# subset by date
met.rng <- met_subs$Date<=dat.rng[2] & met_subs$Date>=dat.rng[1]
met_subs <- met_subs[met.rng,]

##
# custom theme, mod of theme_bw

my_theme <- theme(
  legend.title = element_blank(),legend.position = 'top',
  axis.title.x = element_blank(),legend.box= 'horizontal',
  plot.margin= unit(c(0, 1, 0, 1), "lines") # top right bottom left
  )

# function for setting range on y axis
rng.fun<-function(vec.in){
  rngs<-range(vec.in,na.rm=T)
  buffs<-0.07*abs(diff(rngs))
  c(rngs[1]-buffs,rngs[2]+buffs)
  }

##
# metab plot
to_plo1 <- melt(met_subs, id.var = c('Date'), 
  measure.var = grep('Pg|Rt|NEM', names(met_subs), value = T)
  )
to_plo1$Input <- 'Observed'
to_plo1$Input[grep('dtd', to_plo1$variable)] <- 'Filtered'
to_plo1$Input <- factor(to_plo1$Input, levels = c('Observed', 'Filtered'))
to_plo1$variable <- gsub('_dtd', '', to_plo1$variable)

ylab<-expression(paste('g ',O [2], ' ', m^-2, d^-1))
p1 <- ggplot(to_plo1, aes(x = Date, y = 0.032 * value, group = variable,
    colour = variable)) +
  geom_line() +
  theme_bw() +
  geom_point(size = 2) +
  facet_wrap(~Input, ncol = 1) +
  scale_y_continuous(ylab)  +
  my_theme

print(p1)

@

% moving correlations
\centering\vspace*{\fill}
<<move_corrs, cache = T, fig.height = 5, fig.width = 5.5, out.width = '0.8\\textwidth', eval = T, echo = F, fig.cap = 'Correlations of sun angle with tidal change (as an angular rate) using a half-window width of 12 days.  Correlations larger or smaller than zero are periods when weighted regression may not effectively quantify variation from biological and physical sources in \\ac{DO} time series due to collinearity.'>>=
######
load('data/angle_tide_its.RData')

tmp <- do.call('cbind', angle_tide_its)

# file to upload, doesn't matter which for dates
load(paste0('wtreg/ELKVM_wtreg_1.RData'))
dat <- get(gsub('\\.RData$', '', 'ELKVM_wtreg_1.RData'))

tmp <- data.frame(DateTimeStamp = dat$DateTimeStamp, tmp)
tmp <- melt(tmp, id.var = 'DateTimeStamp')
tmp$daywin <- gsub('^X|\\..*$', '' ,tmp$variable)
tmp$case <- gsub('^X[0-9]*\\.', '', tmp$variable)

# show 12 day half window
daywin <- '12'
to_plo <- tmp[tmp$daywin %in% daywin, ]

my_theme <- theme(
  legend.position = 'top',
  axis.title.x = element_blank(),legend.box= 'horizontal',
  plot.margin= unit(c(0, 1, 0, 1), "lines") # top right bottom left
  )

# plot
p1 <- ggplot(to_plo, 
    aes(x = DateTimeStamp, y = value)) + 
  geom_line() + 
  facet_wrap(~ case, ncol = 1) + 
  theme_bw() + 
  ylab('Correlation') +
  scale_y_continuous(limits= c(-0.5, 0.5)) +
  geom_hline(yintercept = 0, linetype = 'dashed', colour = 'red') +
  my_theme

print(p1)

@

% plots of summarized metabolism estimates, before/after detiding
% all case studies
\centering\vspace*{\fill}
<<metab_sum, cache = T, eval = T, echo = F, fig.height = 5.5, fig.width = 7, fig.cap = 'Means and standard errors of daily metabolism estimates (gross production, total respiration) averaged by month.  Averaged results are shown for observed and filtered \\ac{DO} time series.  May was removed from Rookery Bay because of incomplete data.'>>=

# load metabolism dataa
load('data/met_ls.RData')

# subset metab estimates by window widhts for each case study
load('data/case_grds.RData')
sel_vec <- llply(
  casewins, 
  .fun = function(x) with(case_grds, which(dec_time == x[[1]] & hour == x[[2]] & Tide == x[[3]]))
)
sel_vec <- paste0(names(casewins), '_wtreg_', unlist(sel_vec), '.RData')
met_sub <- met_ls[names(met_ls) %in% sel_vec]

# creat weekly, monthly, seasonal categories
met_sub <- llply(met_sub, 
  .fun = function(x){
    
    # month cols
    x$Month <- format(x$Date, '%m')
    
    x
    
  })

# aggregate by weekly, monthly, seasonal categories
agg_sum <- llply(names(met_sub), 
  .fun = function(x){
    
    station <- gsub('_.*$', '', x)
    x <- met_sub[[x]]
    
    # metabolism column names
    met_cols <- c('Pg', 'Rt', 'Pg_dtd', 'Rt_dtd')
    
    # melt by weekly, monthly, seasonal cats
    # change here for cats to includes
    x <- melt(x, measure.var = c('Month'),
      id.var = c('Date', met_cols)
      )
    
    agg_res <- dlply(x,
      .var = 'variable', 
      .fun = function(y){
        
        out <- vector('list', length = length(met_cols))
        names(out) <- met_cols
        for(met in met_cols){
          
          tmp <- summarySE(y, measurevar = met, groupvars = 'value',
            narm = T) 
          names(tmp)[names(tmp) %in% met] <- 'mean'
          tmp$var <- met
          out[[met]] <- tmp
           
        }
        
        # combine metabolism categories
        out <- do.call('rbind', out)
        
      })
    
    # combine time categories
    agg_res <- agg_res[[1]]
    
    # separate var column into metabolis, obs/dtd
    agg_res$var[!grepl('dtd',agg_res$var)] <- paste0(
      agg_res$var[!grepl('dtd',agg_res$var)], '_obs')
      
    agg_res$sub_var <- gsub('^[A-Z,a-z]*_', '', agg_res$var)
    agg_res$var <- gsub('_[a-z]*$', '', agg_res$var)
    
    agg_res$station <- station
    
    agg_res
    
  })

to_plo <- do.call('rbind', agg_sum)

# reassign factor labels
to_plo$value <- factor(to_plo$value, levels = c('01', '02', '03', '04',
  '05', '06', '07', '08', '09', '10', '11', '12'), 
  labels = c('1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11',' 12')
  )
to_plo$var <- factor(to_plo$var, levels = c('Pg', 'Rt', 'NEM'), 
  labels = c('Pg', 'Rt', 'NEM'))
to_plo$sub_var <- factor(to_plo$sub_var, levels = c('dtd', 'obs'), 
  labels = c('Filtered', 'Observed'))
to_plo$station <- factor(to_plo$station, 
  levels = c('ELKVM', 'PDBBY', 'RKBMB', 'SAPDC'),
  labels = c('Elkhorn Slough', 'Padilla Bay', 'Rookery Bay', 
    'Sapelo Island')
  )

# remove may from RKB, lots of missing values
# remove may from Rookery Bay, lots of missing data
to_plo[to_plo$station %in% 'Rookery Bay'  & to_plo$value %in% '5', c('mean', 'sd', 'se', 'ci')] <- NA

# convert metab data to g m^-2 d^-1
#  1mmolO2 = 32 mg O2, 1000mg = 1g, multiply by 32/1000
to_plo[, c('mean', 'sd', 'se', 'ci')] <- 0.032 * to_plo[, c('mean', 'sd', 'se', 'ci')]

ylab <- expression(paste('g ', O [2], ' ', m^-2, d^-1))
p <- ggplot(to_plo, aes(x = factor(value), y = mean, group = sub_var,
    colour = sub_var)) +
  geom_hline(yintercept = 0, linetype = 'dashed') +
  geom_line() +
  geom_point() + 
  geom_errorbar(aes(ymin = mean - se, ymax = mean + se), 
    width=.3) +
  facet_grid(station ~ var, scales = 'free') +
  theme_bw() +
  scale_y_continuous(ylab) + 
  scale_x_discrete(name = element_blank()) +
  theme(
    legend.position = 'top',
    legend.title = element_blank(),
    plot.margin= unit(rep(0, 4), "lines"),
    axis.text = element_text(size = 8)
    )

print(p)

@
\vfill
\clearpage

%%%%%%
% tables

\section{Tables}

% summary of simulation performance for detided and biological, sim parameters
<<dtd_perf1, cache = F, echo = F, eval = T, results = 'asis'>>=

# uses 'mod_perf' from, see readme
load('data/mod_perf.RData')

# calculate mean, se for dtd_cor and dtd_err
dtd_perf <- llply(names(mod_perf)[2:8], # note indexing
  .fun = function(x) {
    ddply(
      mod_perf,
      .variables = x,
      .fun = function(y) {
        c(
          min(y$cor),
          quantile(y$cor, 0.25),
          median(y$cor),
          quantile(y$cor, 0.75),
          max(y$cor),
          min(y$err),
          quantile(y$err, 0.25),
          median(y$err),
          quantile(y$err, 0.75),
          max(y$err)
        )
    })}
  )

# rename first column for combining, create column for parameter,  then combine
dtd_perf <- lapply(dtd_perf, 
  function(x) { 
    Parameter <- names(x)[1]
    names(x)[1] <- 'Level'
    x[,1] <- factor(x[,1])
    Parameter <- rep(Parameter, nrow(x))
    x <- data.frame(Parameter, x)
    x
    }
  )
dtd_perf <- do.call('rbind', dtd_perf)
names(dtd_perf) <- c('Parameter', 'Level', 'Min cor', 'Low cor', 'Median cor', 'High cor', 'Max cor', 'Min err', 'Low err', 'Median err', 'High err', 'Max err')

# subset by DO time series conditions
to_tab <-dtd_perf[!dtd_perf$Parameter %in% c('dec_time', 'hour', 'Tide'), ]
  
# names for row categories in table
Parms <- c('$\\boldsymbol{DO_{die}}$', 
  '$\\boldsymbol{DO_{adv}}$',  
  '$\\boldsymbol{\\varepsilon_{pro}}$', 
  '$\\boldsymbol{\\varepsilon_{obs}}$'
  )
tab <- form_fun(to_tab[, -c(1:2)])
rows <- to_tab[, 2]
cap.val<-'Summary (range, median, quartiles) of correlations and error estimates comparing filtered and biological \\ac{DO} time series for different simulation parameters ($DO_{die}$, $DO_{adv}$, $\\varepsilon_{pro}$, $\\varepsilon_{obs}$).  Values represent averages from multiple simulations with common parameters.  For example, row one is a summary of all simulations for which the diel \\ac{DO} component was zero ($n=729$).  See \\cref{fig:err_surf1} for results of all parameter combinations.'

# foot.val<-'\\footnotesize \\textit{Note:} test' 

latex( 
  tab,
  file = '',
  where = 'h',
  rowlabel = 'Parameter',
#   insert.bottom = foot.val,
  caption = cap.val,
  caption.loc = 'top',
  rgroup = Parms,
  n.rgroup = rep(3, 4),
  cgroup = c('Correlation', 'RMSE'),
  n.cgroup = c(5, 5),
  rowname = rows,
  colheads=rep(c('Min', '25\\textsuperscript{th}', 'Median', '75\\textsuperscript{th}', 'Max'),2),
  label = 'tab:dtd_perf1'
  )
@

% summary of simulation performance for detided and biological, window widths
<<dtd_perf2, cache = F, echo = F, eval = T, results = 'asis'>>=

# uses 'mod_perf' from 'dep_data.rnw'
load('data/mod_perf.RData')

# calculate median, se for dtd_cor and dtd_err
dtd_perf <- llply(names(mod_perf)[1:8],
  .fun = function(x) {
    ddply(
      mod_perf,
      .variables = x,
      .fun = function(y) {
        c(
          min(y$cor),
          quantile(y$cor, 0.25),
          median(y$cor),
          quantile(y$cor, 0.75),
          max(y$cor),
          min(y$err),
          quantile(y$err, 0.25),
          median(y$err),
          quantile(y$err, 0.75),
          max(y$err)
        )
    })}
  )

# rename first column for combining, create column for parameter,  then combine
dtd_perf <- lapply(dtd_perf, 
  function(x) { 
    Parameter <- names(x)[1]
    names(x)[1] <- 'Level'
    x[,1] <- factor(x[,1])
    Parameter <- rep(Parameter, nrow(x))
    x <- data.frame(Parameter, x)
    x
    }
  )
dtd_perf <- do.call('rbind', dtd_perf)
names(dtd_perf) <- c('Parameter', 'Level', 'Min cor', 'Low cor', 'Median cor', 'High cor', 'Max cor', 'Min err', 'Low err', 'Median err', 'High err', 'Max err')

# subset by windows
to_tab <-dtd_perf[dtd_perf$Parameter %in% c('dec_time', 'hour', 'Tide'), ]
  
# names for row categories in table
Parms <- c('Days', 'Hours', 'Tide')

tab <- form_fun(to_tab[, -c(1:2)])
rows <- to_tab[, 2]
cap.val<-'Summary (range, median, quartiles) of correlations and error estimates comparing filtered and biological \\ac{DO} time series for simulations using different half window widths in the weighted regressions (days, hours, and proportion of tidal range).  Values represent averages from multiple simulations with common window values. For example, row one is a summary of all simulations for which the half window width was one day ($n=729$). See \\cref{fig:err_surf2} for results of all window combinations.'

# foot.val<-'\\footnotesize \\textit{Note:} test' 

latex( 
  tab,
  file = '',
  rowlabel = 'Window',
#   insert.bottom = foot.val,
  caption = cap.val,
  caption.loc = 'top',
  rgroup = Parms,
  n.rgroup = rep(3, 3),
  cgroup = c('Correlation', 'RMSE'),
  n.cgroup = c(5, 5),
  rowname = rows,
  colheads=rep(c('Min', '25\\textsuperscript{th}',  'Median', '75\\textsuperscript{th}', 'Max'),2),
  label = 'tab:dtd_perf2'
  )
@

% descriptive table of case studies
<<case_att, cache = F, echo = F, eval = T, results = 'asis'>>=

# ######
# # table of case study characteristics
# # uses local files not in project....
# 
# cases <- c('ELKVM','PDBBY', 'RKBMB', 'SAPDC')
# 
# ##
# # get amps (m) of dominant tidal constituents
# 
# files <- list.files('M:/wq_models/SWMP/raw/rproc/proc5/', 
#   pattern = paste(cases, collapse = '|'), 
#   full.names = T)
# file_ls <- list()
# for(file in files){
#   load(file)
#   nm <- gsub('.RData', '', basename(file))
#   tmp <- get(nm)
#   mod <- oce::tidem(tmp$Depth, tmp$DateTimeStamp, 
#     constituents = c('P1', 'O1', 'M2', 'S2'))
#   const <- attr(mod, 'data')$amplitude[-1]
#   names(const) <- attr(mod, 'data')$name[-1]
#     
#   file_ls[[nm]] <- const
#   }
# tide_comps<- data.frame(do.call('rbind', file_ls))
# tide_comps$site <- rownames(tide_comps)
# 
# ##
# # get mean wq vals
# 
# files <- list.files('M:/wq_models/SWMP/raw/rproc/proc5/', 
#   pattern = paste(cases, collapse = '|'), 
#   full.names = T)
# file_ls <- list()
# for(file in files){
#   load(file)
#   nm <- gsub('.RData', '', basename(file))
#   cat(nm, '\t')
#   tmp <- get(nm)
#   file_ls[[nm]] <- tmp
#   }
# 
# wq_sums <- adply(
#   file_ls, 1, 
#   function(x) {
#     DO <- mean(x$DO_mgl, na.rm = T)
#     chl <- mean(x$CHLA_N, na.rm = T)
#     sal <- mean(x$Sal, na.rm = T)
#     temp <- mean(x$Temp, na.rm = T)
#     data.frame(DO, chl, sal, temp)
#     }
#   )
# names(wq_sums)[1] <- c('site')
# 
# ##
# # get metab summaries
# 
# # metab data
# # this is for observed data so, doesn't matter which index number
# load('data/met_ls.RData')
# 
# met_sum <- adply(matrix(cases, ncol = 1),
#   1,
#   .fun = function(x){
#     
#     met <- met_ls[[paste0(x, '_wtreg_1.RData')]][, c('Pg', 'Rt', 'NEM')]
#     colMeans(met, na.rm = T)
#      
#     }
#   )
# met_sum$X1 <- NULL
# met_sum$site <- cases
# 
# ##
# # combine data 
# # tide_comps, daily_do, met_sum
# 
# to_tab <- cbind(tide_comps, wq_sums, met_sum)
# to_tab <- to_tab[, !names(to_tab) %in% 'site']
# 
# case_tab <- to_tab
# save(case_tab, file = 'case_tab.RData')

load('data/case_tab.RData')

# convert metab data to g m^-2 d^-1
#  1mmolO2 = 32 mg O2, 1000mg = 1g, multiply by 32/1000
tab <- case_tab
tab[, c('Pg', 'Rt', 'NEM')] <- 0.032 * tab[, c('Pg', 'Rt', 'NEM')]
tab <- form_fun(tab)
rows <- rownames(tab)

cap.val<-'Summary statistics of tidal component amplitudes (m), selected water quality parameters (\\ac{DO} mg L$^{-1}$, chlorophyll-a $\\mu$g L$^{-1}$, salinity psu, water temperature $^{\\circ}$C)  and metabolism estimates (gross production, respiration, and net ecosystem metabolism as g m$^{-2}$ d$^{-1}$ based on observed data) for each case study.  Tidal components are principal lunar semidiurnal (O1, frequency 25.82 hours), solar diurnal (P1, 24.07 hours), lunar semidiurnal (M2, 12.42 hours), and solar semidiurnal (S2, 12 hours) estimated from harmonic regressions of tidal height (\\texttt{oce} package in R, \\citealt{Foreman89}, \\citetalias{RDCT14}).  Water quality data are averages for the entire period of record for each site.  Metabolism estimates are means of daily integrated values.'

foot.val<-'\\footnotesize\\textsuperscript{\\textit{a}}Pg: gross production, Rt: respiration, NEM: net ecosystem metabolism, estimated using methods described herein with observed data'

latex( 
  tab,
  file = '',
  rowlabel = 'Site',
  insert.bottom = foot.val,
  caption = cap.val,
  caption.loc = 'top',
  cgroup = c('Tidal amplitude', 'Water quality', 'Metabolism\\textsuperscript{\\textit{a}}'),
  n.cgroup = c(4, 4, 3),
  rowname = rows,
  colheads=c('O1', 'P1', 'M2', 'S2', 'DO', 'Chl', 'Sal', 'Temp', 'Pg', 'Rt', 'NEM'),
  label = 'tab:case_att'
  )

@

% correlations with tide before/after wtreg
<<cor_res, cache = F, echo = F, eval = T, results = 'asis'>>=
# #####
# # table of DO/metab correlations with tide before after, detiding
# # note that tide in met_ls is daily average (day or night) of hourly tidal change
# 
# # metab and inst flux data
# load('data/met_ls.RData')
# # load('data/met_ls_inst.RData')
# load('data/case_grds.RData')
# 
# # go through each site for DO cors, use metab list for metab cors
# case_regs <- list.files('wtreg', '_wtreg_[0-9]*.RData')
# cor_res <- alply(matrix(case_regs),
#   1, 
#   .progress = 'tk',
#   .fun = function(x){
#   
#     # load wtreg data
#     load(paste0('wtreg/', x))
#     nm <- gsub('.RData', '', x)
#     dat_in <- get(nm)
#       
#     # add month column
#     dat_in$month <- strftime(dat_in$Date, '%m')
#     
#     # DO obs v tide
#     do_obs <- ddply(
#       dat_in, 
#       .variable = c('month'), 
#       .fun = function(x) with(x, cor.test(DO_obs, Tide)$estimate)
#     )
#     
#     # DO dtd v tide
#     do_dtd <- ddply(
#       dat_in, 
#       .variable = c('month'), 
#       .fun = function(x) with(x, cor.test(DO_nrm, Tide)$estimate)
#     )
#     
#     # get tidal range for metabolic day/night periods from flux_in
#     # for correlation with daily integrated metab
#     tide_rngs <- ddply(dat_in, 
#       .variables = c('met.date'),
#       .fun = function(x){
#         
#         # mean tidal derivative for day hours
#         sunrise <- mean(diff(x[x$variable %in% 'sunrise', 'Tide'], 
#           na.rm = T))
#         
#         # mean tidal derivative for night hours
#         sunset <- mean(diff(x[x$variable %in% 'sunset', 'Tide'], 
#           na.rm = T))
#         if(sunrise == 'Inf') sunrise <- NA
#         if(sunset == 'Inf') sunset <- NA
#         
#         # mean tidal derivative for metabolic day
#         daytot <- mean(diff(x$Tide, na.rm = T))
#         
#         c(daytot, sunrise, sunset)
#         
#         }
#       )
#     names(tide_rngs) <- c('Date','daytot', 'sunrise', 'sunset')
#     
#     # get metab data from list
#     dat_in <- met_ls[[x]]
#     dat_in <- merge(dat_in, tide_rngs, by = 'Date', all.x = T)
#     dat_in$month <- strftime(dat_in$Date, '%m')
#     
#     # Pg values correlated with tidal range during sunlight hours
#     # Rt values correlated with tidal range during night hours
#     # NEM values correlated with metabolic daily tidal range
#     # NA if error is returned in correlation
#     erf<- function(e) NA
#     met_cor <- ddply(
#         dat_in, 
#         .variable = c('month'), 
#         .fun = function(x){
#           
#           with(x, {c(
#             Pg_obs = tryCatch(cor.test(Pg, sunrise)$estimate, error = erf),
#             Rt_obs = tryCatch(cor.test(Rt, sunset)$estimate, error = erf),
#             NEM_obs = tryCatch(cor.test(NEM, daytot)$estimate, error = erf),
#             Pg_dtd = tryCatch(cor.test(Pg_dtd, sunrise)$estimate, error = erf),
#             Rt_dtd =  tryCatch(cor.test(Rt_dtd, sunset)$estimate, error = erf),
#             NEM_dtd = tryCatch(cor.test(NEM_dtd, daytot)$estimate, error = erf)
#           )})
#           
#         }
#       )
#     names(met_cor) <- gsub('\\.cor$', '', names(met_cor))
#     
#     # DO and metab corrs combined
#     res_sum <- data.frame(met_cor, do_obs = do_obs$cor, do_dtd = do_dtd$cor)
#     
#     # add column for sim name
#     res_sum$L1 <- nm
#     
#     res_sum
#     
#   })
# names(cor_res) <- case_regs
# cor_res <- do.call('rbind', cor_res)
# row.names(cor_res) <- 1:nrow(cor_res)
# 
# cor_res$site <- gsub('_wtreg_[0-9]*$', '', cor_res$L1)
# cor_res$wins <- as.numeric(gsub('^.*_wtreg_', '', cor_res$L1))
# 
# # merge with case_grds
# case_grds$wins <- as.numeric(row.names(case_grds))
# cor_res <- merge(cor_res, case_grds, by = 'wins', all.x = T)
# 
# cor_res <- melt(cor_res, measure.var = c('Pg_obs', 'Rt_obs', 'NEM_obs', 'Pg_dtd', 'Rt_dtd', 'NEM_dtd', 'do_obs', 'do_dtd'))
# 
# # create columns for variable (DO, flux, etc.) and sub variable (obs, dtd)
# cor_res$sub_var <- gsub('^.*_', '', cor_res$variable)
# cor_res$var <- gsub('_.*$', '', cor_res$var)

load('data/cor_res.RData')

# subset metab estimates by window widhts for each case study
load('data/case_grds.RData')
sel_vec <- llply(
  casewins, 
  .fun = function(x) with(case_grds, which(dec_time == x[[1]] & hour == x[[2]] & Tide == x[[3]]))
)
sel_vec <- paste0(names(casewins), '_wtreg_', unlist(sel_vec))

cor_res <- cor_res[cor_res$L1 %in% sel_vec, ]

# make wide form, take monthly averages of correlations
to_tab <- dcast(cor_res, site + sub_var ~ var, value.var = 'value', 
  fun.aggregate = function(x) mean(x, na.rm = T))

# reorder rows, columns for plot
to_tab$sub_var <- factor(to_tab$sub_var, levels = c('obs', 'dtd'))
to_tab <- to_tab[with(to_tab, order(site, sub_var)), ]
to_tab <- to_tab[, c('site', 'sub_var', 'do', 'Pg', 'Rt', 'NEM')]

# combine both tables
tab <- to_tab
rows <- as.character(tab$site)
tab <- form_fun(tab[, -c(1:2)])

# remove NEM
tab <- tab[, !names(tab) %in% 'NEM']

cap.val<-'Correlations of tidal changes at each site with continuous \\ac{DO} observations and metabolism estimates (gross production, respiration) before (observed) and after (filtered) filtering with weighted regression.  Values are averages of monthly correlations.  \\ac{DO} values are correlated with predicted tidal height at each observation, whereas metabolism estimates are correlated with mean tidal height change between observations during day or night periods for production and respiration, respectively.'

foot.val<-'\\textsuperscript{\\textit{a}}Pg: gross production, Rt: respiration, NEM: net ecosystem metabolism' 

latex( 
  tab,
  file = '',
  rowlabel = 'Site',
  rgroup = unique(rows), 
  n.rgroup = rep(2, 4),
  insert.bottom = foot.val,
  caption = cap.val,
  colheads = c('DO', 'Pg\\textsuperscript{\\textit{a}}', 'Rt'),
  caption.loc = 'top',
  rowname = rep(c('Observed', 'Filtered'), 4),
  label = 'tab:cor_res'
  )

@

% case study metabolism results, including perc anom
<<case_res, cache = F, echo = F, eval = T, results = 'asis'>>=
# # metab estimates for each wtreg
# load('data/met_ls.RData')
# 
# met_comp <- ldply(met_ls, function(x){
#   
#   # detided
#   anoms <- 100 * anoms.fun(x, pgvar = 'Pg_dtd', rtvar = 'Rt_dtd')
#   anoms <- data.frame(variable = 'Anom', anoms)
#   anoms <- melt(anoms, id.var = 'variable', variable.name = 'X1')[, c(2, 1, 3)]
#   subs <- na.omit(x[, c('Pg_dtd', 'Rt_dtd', 'NEM_dtd')])  
#   sums <- adply(t(subs),
#     1, 
#     function(y) data.frame(Avg = mean(y), sd = sd(y))
#     )
#   sums <- melt(sums, id.var = 'X1')
#   dtd <- rbind(anoms, sums)
#   dtd$X1 <- gsub('_dtd', '', dtd$X1)
#   dtd$Input <- 'Detided'
#   
#   # observed
#   anoms <- 100 * anoms.fun(x, pgvar = 'Pg', rtvar = 'Rt')
#   anoms <- data.frame(variable = 'Anom', anoms)
#   anoms <- melt(anoms, id.var = 'variable', variable.name = 'X1')[, c(2, 1, 3)]
#   subs <- na.omit(x[, c('Pg', 'Rt', 'NEM')])  
#   sums <- adply(t(subs),
#     1, 
#     function(y) data.frame(Avg = mean(y), sd = sd(y))
#     )
#   sums <- melt(sums, id.var = 'X1')
#   obs <- rbind(anoms, sums)
#   obs$Input <- 'Observed'  
#   
#   # output
#   out <- rbind(dtd, obs)
#   names(out) <- c('Metab', 'Metric', 'Value', 'Input')
#   
#   return(out)
#   
#   })
# 
# save(met_comp, file = 'data/met_comp.RData')

load('data/met_comp.RData')

# subset metab estimates by window widths for each case study
load('data/case_grds.RData')
sel_vec <- llply(
  casewins, 
  .fun = function(x) with(case_grds, which(dec_time == x[[1]] & hour == x[[2]] & Tide == x[[3]]))
)
sel_vec <- paste0(names(casewins), '_wtreg_', unlist(sel_vec), '.RData')

met_comp <- met_comp[met_comp$.id %in% sel_vec, ]

to_tab <- met_comp
names(to_tab)[1] <- 'Site'

# convert metab data to g m^-2 d^-1
#  1mmolO2 = 32 mg O2, 1000mg = 1g, multiply by 32/1000
sel_vec <- !to_tab$Metric %in% 'Anom'
to_tab$Value[sel_vec] <- 0.032 * to_tab$Value[sel_vec]

# make columns as factors for correct row, column order w/ dcast
to_tab$Input <- factor(to_tab$Input, levels = c('Observed', 'Detided'), labels = c('Observed', 'Filtered'))
to_tab$Metab <- factor(to_tab$Metab, levels = c('Pg', 'Rt', 'NEM'))
to_tab$Metric <- factor(to_tab$Metric, levels = c('Avg', 'sd', 'Anom'))

# dcast long to wide
to_tab <- dcast(to_tab, Site + Input ~ Metab + Metric, value.var = 'Value')

# remove extra text on site variable
to_tab$Site <- gsub('_wtreg_[0-9]*.RData$', '', to_tab$Site)

# remove NEM columns
to_tab <- to_tab[, !grepl('^NEM', names(to_tab))]

# names for row categories in table

tab <- form_fun(to_tab[, -c(1:2)])
rows <- to_tab[, 2]
cap.val<-'Summary of metabolism estimates (gross production, respiration) for case studies using \\ac{DO} time series before (observed) and after (filtered) filtering with weighted regression.  Means and standard deviation are based on daily integrated metabolism estimates.  Anomalous values are the percentage of metabolism estimates that were negative for gross production and positive for respiration.'

foot.val<-'\\textsuperscript{\\textit{a}}Pg: gross production, Rt: respiration' 
latex( 
  tab,
  file = '',
  rowlabel = 'Site',
  insert.bottom = foot.val,
  caption = cap.val,
  caption.loc = 'top',
  rgroup = unique(to_tab$Site),
  n.rgroup = rep(2, 4),
  cgroup = c('Pg\\textsuperscript{\\textit{a}}', 'Rt'),
  n.cgroup = c(3, 3),
  rowname = rows,
  colheads=c(rep(c('Mean','SD', 'Anom'),2), c('Mean', 'SD')),
  label = 'tab:case_res'
  )
@

\end{document}